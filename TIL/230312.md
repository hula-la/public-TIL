# MSA

#### API 멱등성과 데이터의 순서 보장

- `Exactly once (enable.idempotence = true)` : Kafka에는 `정확히 한번 전송`을 보장하는 옵션이 있음
  - Producer -> Broker -> Topic 간의 멱등성이 보장됨
  - Session 단위에서 유효한 기능으로 Producer App이 재시작하는 경우 멱등성이 보장되지 않음.
- `PK Error`
  - 따로 멱등성 보장을 위한 장치를 하지 않고, 변경된 데이터를 전송할 때 `PK 정보`를 포함해 전송하여 중복된 데이터 발생 시 DB PK Error 로 종단 간 멱등성을 보장할 수 있음.
  - 이 방식은 구현이 간단하며 서버 구축 및 운영 리소스를 적게 사용한다는 장점이 있음. 다만, 완전한 종단간 멱등성 보장을 위해서는 데이터의 순서가 보장되어야 함.

- 순서 보장
  - PK를 Kafka Message Key로 사용해 Kafka 의 Topic에 Partitioning 함.
  - Partition 내에서 순서가 유지되므로 각 Partition 별로 순서가 유지됨.
  - PK를 Key로 이용하는 경우 Key 값이 단순해서 Hash가 중복되더라도 같은 종류의 message가 같은 Partition 으로 Partitioning 되므로 같은 데이터에 대해서 데이터 로직의 순서를 유지할 수 있음.
  - **1개의 Partition에 대해서 1개의 Consumer(같은 Consumer group 내에서)가 처리함. 따라서 이 경우 동시성 처리는 Kafka의 Partition 개수에 따라 결정됨.**
  - Concurrency 성능이 partition 에 의존적이며, Partition이 증가할수록 Kafka Broker, 서비스의 Heap Memory 등에 영향을 줌.
  - Partition에 대응되어 Consumer의 수가 늘어나면, Consumer 수가 늘어날수록 Consumer Rebalancing 시간도 증가함.

- **Consumer의 Multi Threading 와 Concurrency 성능**

  - Kafka가 대용량 데이터 처리에 특화되어 있지만, 멀티 스레딩 처리를 하지 않으면 Concurrency 성능이 Partition의 갯수로 제한됩니다.

  - Partition 개수로만 Concurrency 성능이 조절된다면 Partition 개수의 변화가 있어야 하는데, 성능 조절을 위해 Partition 변경시 Key 와 Partition의 Mapping이 변경되는 Partition Rebalancing이 발생합니다. 또한 Partition은 *비싼*자원에 속해 갯수 증가를 신중히 고민해야 합니다. [링크](https://www.confluent.io/ko-kr/blog/how-choose-number-topics-partitions-kafka-cluster/)

  - 또, Partition에 대응되는 Consumer 수가 증가할 수록 Consumer Rebalance 시간이 증가합니다.

  - Concurrency 성능을 위해서는 Partition은 고정해두고 Thread의 갯수로 Concrrency 성능을 조정하는 것이 좋음

  - 이 방식의 단점은 데이터의 순서가 보장되지 않는다는 점

#### Topic 설계에 고려할 것들

1. Topic 설계시 가장 중요한 것은, 순서를 유지해야하는 것은 동일 topic에 두며 동일한 파티션 키를 사용하는 것
2. 한 entity가 다른 entity에 종속되어 있는 경우나 함께 자주 필요한 경우 동일한 topic에 배치하는 것이 좋음.
3. 특정 entity가 다른 entity보다 훨씬 높은 이벤트 비율을 갖는 경우 쓰기 처리량이 낮은 entity만 원하는 consumer를 위해 topic을 분리하는 것이 좋음 (처리량이 낮은 entity가 처리량 높은 entity의 영향을 덜 받기 위한)

### 돌고 돌아 Batch 로…

현재 솔루션에서 가장 중요한 것은 데이터 정합성입니다. 따라서 가장 간단하면서 정확한 방법인 Batch로 정합성을 맞추기로 결정했습니다. 두 테이블간 잘못된 데이터를 확인하고 Origin Table을 기준으로 데이터를 보정하고 Slack ss알림을 보냈습니다. 대부분의 데이터는 Kafka를 통해 전송하고, 잔여 데이터를 Batch로 처리하는 것이기에 Batch 로 데이터를 보정해도 문제가 없었습니다.

#### Transaction

- Saga Pattern 을 이용한 분산 트랜잭션 

마이크로서비스 끼리 이벤트를 주고 받다 특정 서비스에서 작업이 실패하는 경우, 이전까지 완료된 작업들에 대해서 보상 이벤트를 보내 분산환경에서 원자성을 보장하는 패턴입니다. SAGA 패턴의 핵심은 트랜잭션의 관리 주체가 DB가 아닌 APP에 있다는 것입니다.

예를 들어 A - B App에서 DB가 MS로 연결되어 있다면 A 성공 후 B가 실패하는 경우 B에서 A를 향해 트랜잭션 실패 이벤트를 발행합니다. 그걸 받은 A는 트랜잭션 롤백을 합니다.

- Saga Pattern은 Choreography와 Orchestration 두가지 종류가 존재합니다
  - Choreography는 이벤트를 순차적으로 받은 뒤 성공한 마지막 App에서 완료 트랜잭션을 보냅니다. 구성하기 편하지만, 트랜잭션의 현재 상태를 알기 어렵습니다.
  - Orchestration은 중간에 Orchestration하는 Saga Instance가 별도로 존재해 트랜잭션 내의 App들은 모두 Saga를 거쳐가도록합니다. 인프라 구현은 복잡해지지만 트랜잭션 현재 상태를 쉽게 알고 롤백하기 쉽습니다.
